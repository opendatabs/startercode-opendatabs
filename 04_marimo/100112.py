# /// script
# requires-python = ">=3.12"
# dependencies = [
#     "marimo",
#     "matplotlib==3.10.6",
#     "missingno==0.5.2",
#     "pandas==2.3.2",
#     "polars==1.32.3",
#     "requests==2.32.5",
# ]
# ///

import marimo

__generated_with = "0.15.1"
app = marimo.App(auto_download=["html"])


@app.cell
def _():
    import marimo as mo
    return (mo,)


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## Open Government Data, provided by **Statistisches Amt des Kantons Basel-Stadt - DCC Data Competence Center**
    *Autogenerated Python starter code for dataset with identifier* **100112**
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## Dataset
    # **Geschwindigkeitsmonitoring: Kennzahlen pro Mess-Standort**
    **Description**: <p>In diesem Datensatz werden zu jeder Messung (ein Messgerät an einem Standort) die Kennzahlen V50, V85, Anzahl Fahrzeuge und Übertretungsquote pro Richtung angegeben. Die einzelnen Fahrten finden Sie im Datensatz Einzelmessungen (<a href="https://data.bs.ch/explore/dataset/100097//" target="_blank">https://data.bs.ch/explore/dataset/100097/</a>)</p><p class="MsoNormal" style="margin-bottom: 12pt; line-height: normal; background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial;"><span style="font-size: 10.5pt; font-family: Arial, sans-serif;">Bei den dargestellten
Daten handelt es sich ausschliesslich um statistische Erhebungen. Diese stehen
nicht in einem Zusammenhang mit Ordnungsbussen oder einer strafrechtlichen
Verfolgung. Die statistischen Geschwindigkeitsmessungen dienen der
Kantonspolizei Basel-Stadt zur Überprüfung der Geschwindigkeit sowie der
Verkehrssicherheit (z.B. Sicherheit an Fussgängerstreifen) an der betreffenden
Örtlichkeit. Die Ergebnisse dienen zur Entscheidung, an welchen Örtlichkeiten
Handlungsbedarf in Form von Geschwindigkeitskontrollen besteht. Jedes
Statistikgerät besitzt eine einzige Punktgeometrie und ist meist mit zwei
Richtungen versehen (Richtung 1 und 2).<o:p></o:p></span></p><p class="MsoNormal" style="margin-bottom: 12pt; line-height: normal; background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial;"><span style="font-size: 10.5pt; font-family: Arial, sans-serif;">Hinweis: Die
Messungen sind nicht zwingend repräsentativ für das ganze Jahr und müssen im
Kontext des Erhebungsdatums betrachtet werden. Darüber hinaus wurden gewisse
Messungen während einer ausserordentlichen Verkehrsführung (z.B.
Umleitungsverkehr infolge von Baustellentätigkeiten etc.) erhoben.
Manipulationen an Geräten können zu fehlerhaften Messungen führen.</span></p><p class="MsoNormal" style="margin-bottom: 12pt; line-height: normal; background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial;"><font face="Arial, sans-serif">Eine Übersicht aller Datensätze auf dem kantonalen Datenportal zum Geschwindigkeitsmonitoring sind unter </font><a href="https://data.bs.ch/explore/?refine.tags=Geschwindigkeitsmonitoring" style="background-color: rgb(255, 255, 255); font-family: sans-serif; font-size: 14px; font-weight: 400;" target="_blank">https://data.bs.ch/explore/?refine.tags=Geschwindigkeitsmonitoring</a><font face="Arial, sans-serif"> aufrufbar.</font></p><p>Die Mess-Standorte werden auch auf dem Geoportal Basel-Stadt publiziert: <a href="https://www.geo.bs.ch/geschwindigkeitsmonitoring" target="_blank">https://www.geo.bs.ch/geschwindigkeitsmonitoring</a></p>

    *You can find the dataset [under this link](https://data.bs.ch/explore/dataset/100112)*.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    /// details | Metadata

    - **Dataset_identifier** `100112`
- **Title** `Geschwindigkeitsmonitoring: Kennzahlen pro Mess-Standort`
- **Description** `<p>In diesem Datensatz werden zu jeder Messung (ein Messgerät an einem Standort) die Kennzahlen V50, V85, Anzahl Fahrzeuge und Übertretungsquote pro Richtung angegeben. Die einzelnen Fahrten finden Sie im Datensatz Einzelmessungen (<a href="https://data.bs.ch/explore/dataset/100097//" target="_blank">https://data.bs.ch/explore/dataset/100097/</a>)</p><p class="MsoNormal" style="margin-bottom: 12pt; line-height: normal; background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial;"><span style="font-size: 10.5pt; font-family: Arial, sans-serif;">Bei den dargestellten
Daten handelt es sich ausschliesslich um statistische Erhebungen. Diese stehen
nicht in einem Zusammenhang mit Ordnungsbussen oder einer strafrechtlichen
Verfolgung. Die statistischen Geschwindigkeitsmessungen dienen der
Kantonspolizei Basel-Stadt zur Überprüfung der Geschwindigkeit sowie der
Verkehrssicherheit (z.B. Sicherheit an Fussgängerstreifen) an der betreffenden
Örtlichkeit. Die Ergebnisse dienen zur Entscheidung, an welchen Örtlichkeiten
Handlungsbedarf in Form von Geschwindigkeitskontrollen besteht. Jedes
Statistikgerät besitzt eine einzige Punktgeometrie und ist meist mit zwei
Richtungen versehen (Richtung 1 und 2).<o:p></o:p></span></p><p class="MsoNormal" style="margin-bottom: 12pt; line-height: normal; background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial;"><span style="font-size: 10.5pt; font-family: Arial, sans-serif;">Hinweis: Die
Messungen sind nicht zwingend repräsentativ für das ganze Jahr und müssen im
Kontext des Erhebungsdatums betrachtet werden. Darüber hinaus wurden gewisse
Messungen während einer ausserordentlichen Verkehrsführung (z.B.
Umleitungsverkehr infolge von Baustellentätigkeiten etc.) erhoben.
Manipulationen an Geräten können zu fehlerhaften Messungen führen.</span></p><p class="MsoNormal" style="margin-bottom: 12pt; line-height: normal; background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial;"><font face="Arial, sans-serif">Eine Übersicht aller Datensätze auf dem kantonalen Datenportal zum Geschwindigkeitsmonitoring sind unter </font><a href="https://data.bs.ch/explore/?refine.tags=Geschwindigkeitsmonitoring" style="background-color: rgb(255, 255, 255); font-family: sans-serif; font-size: 14px; font-weight: 400;" target="_blank">https://data.bs.ch/explore/?refine.tags=Geschwindigkeitsmonitoring</a><font face="Arial, sans-serif"> aufrufbar.</font></p><p>Die Mess-Standorte werden auch auf dem Geoportal Basel-Stadt publiziert: <a href="https://www.geo.bs.ch/geschwindigkeitsmonitoring" target="_blank">https://www.geo.bs.ch/geschwindigkeitsmonitoring</a></p>`
- **Contact_name** `Open Data Basel-Stadt`
- **Issued** `2021-02-02`
- **Modified** `2026-01-15T02:01:51+00:00`
- **Rights** `NonCommercialAllowed-CommercialAllowed-ReferenceRequired`
- **Temporal_coverage_start_date** `2018-01-01T23:00:00+00:00`
- **Temporal_coverage_end_date** `None`
- **Themes** `['Mobilität und Verkehr']`
- **Keywords** `['Messung', 'Messwert', 'Standort', 'Mess-Stelle', 'Messstelle', 'Geschwindigkeit', 'Verkehr', 'Auto', 'PKW', 'PW', 'LKW', 'LW', 'Radar']`
- **Publisher** `Kantonspolizei`
- **Reference** `None`


    ///
    """
    )
    return


@app.cell
def _():
    import os
    import io
    import pandas as pd
    import requests
    import matplotlib.pyplot as plt
    return os, io, pd, plt, requests


@app.cell
def _(plt):
    plt.style.use("ggplot")

    params = {
        "text.color": (0.25, 0.25, 0.25),
        "figure.figsize": [18, 6],
    }

    plt.rcParams.update(params)
    return


@app.cell
def _(os):
    def ensure_data_dir() -> str:
        data_path = os.path.join(os.getcwd(), "..", "data")
        os.makedirs(data_path, exist_ok=True)
        return data_path
    return (ensure_data_dir,)


@app.cell
def _(io, pd, requests):
    def download_csv_chunk(
        session: requests.Session,
        dataset_id: str,
        extra_params: dict | None = None,
    ) -> pd.DataFrame:
        base_url = "https://data.bs.ch/api/explore/v2.1"
        url = f"{base_url}/catalog/datasets/{dataset_id}/exports/csv"

        params = {
            "timezone": "Europe/Zurich",
            "use_labels": "false",
        }
        if extra_params:
            params.update(extra_params)

        r = session.get(url, params=params)
        r.raise_for_status()

        buf = io.BytesIO(r.content)

        df = pd.read_csv(
            buf,
            sep=";",
            on_bad_lines="warn",
            encoding_errors="ignore",
            low_memory=False,
        )

        return df
    return (download_csv_chunk,)


@app.cell
def _():
    def pick_best_facet(facets_json: dict, max_rows_per_chunk: int) -> tuple[str | None, list[str]]:
        """
        Choose a facet column where each bucket has <= max_rows_per_chunk rows.
        Among all such columns, pick the one with the smallest worst-case bucket.
        Returns (facet_name, list_of_values) or (None, []) if nothing suitable.
        """
        best_name = None
        best_values: list[str] = []
        best_max_bucket = None

        for facet in facets_json.get("facets", []):
            facet_name = facet.get("name")
            value_list = facet.get("facets", [])
            if not facet_name or not value_list:
                continue

            counts = [v.get("count", 0) for v in value_list]
            if not counts:
                continue

            max_bucket = max(counts)
            if max_bucket > max_rows_per_chunk:
                # this facet would still exceed the chunk limit for some values
                continue

            if best_max_bucket is None or max_bucket < best_max_bucket:
                best_max_bucket = max_bucket
                best_name = facet_name
                best_values = [v.get("value") for v in value_list if v.get("value") is not None]

        return best_name, best_values


@app.cell
def _(download_csv_chunk, ensure_data_dir, mo, os, pd, requests):
    def get_dataset(dataset_id: str, max_rows_per_chunk: int = 50_000) -> pd.DataFrame:
        """
        Download a dataset from data.bs.ch.

        - For small datasets (<= max_rows_per_chunk): single CSV export.
        - For large datasets:
            * Inspect /facets to find a good splitting column.
            * Download one CSV per facet value via refine.<col>=<value>.
            * Additionally download rows where that column is NULL via q=#null(<col>).

        The combined result is written to ../data/{dataset_id}.csv and returned as a DataFrame.
        """
        base_url = "https://data.bs.ch/api/explore/v2.1"
        records_url = f"{base_url}/catalog/datasets/{dataset_id}/records"
        facets_url = f"{base_url}/catalog/datasets/{dataset_id}/facets"

        session = requests.Session()
        common_params = {
            "timezone": "Europe/Zurich",
            "use_labels": "false",
        }

        # 1) Get total_count via /records
        r = session.get(records_url, params={**common_params, "limit": 1})
        r.raise_for_status()
        meta = r.json()
        total_count = meta.get("total_count", 0)

        if not isinstance(total_count, int):
            # fall back to simple export if we can't read total_count
            total_count = 0

        # 2) Small dataset: single CSV export
        if total_count == 0 or total_count <= max_rows_per_chunk:
            df = download_csv_chunk(session, dataset_id, extra_params={})
            data_path = ensure_data_dir()
            csv_path = os.path.join(data_path, f"{dataset_id}.csv")
            df.to_csv(csv_path, index=False)
            return df

        # 3) Large dataset: inspect /facets to decide how to split
        r = session.get(facets_url, params=common_params)
        r.raise_for_status()
        facets_json = r.json()

        facet_name, facet_values = pick_best_facet(facets_json, max_rows_per_chunk=max_rows_per_chunk)

        if facet_name is None or not facet_values:
            raise RuntimeError(
                f"Could not find a facet column to split dataset {dataset_id} into "
                f"chunks of <= {max_rows_per_chunk} rows. Please handle this dataset manually."
            )

        dfs: list[pd.DataFrame] = []

        # 4) Download each facet value (refine.<facet_name>=value)
        n_parts = len(facet_values) + 1  # +1 for NULLs

        with mo.status.progress_bar(
            total=n_parts,
            title=f"Lade Datensatz {dataset_id}",
            subtitle=f"Split nach '{facet_name}'…",
        ) as bar:
            # NULLs
            bar.update(subtitle=f"{facet_name} = NULL")
            null_query = {"qv1": f"#null({facet_name})"}
            try:
                df_null = download_csv_chunk(session, dataset_id, extra_params=null_query)
                if not df_null.empty:
                    dfs.append(df_null)
            except requests.HTTPError as e:
                print(f"Warning: NULL download for {facet_name} failed: {e}")
            # non-NULL values
            for v in facet_values:
                bar.update(subtitle=f"{facet_name} = {v!r}")
                params = {"refine": f'{facet_name}:"{v}"'}
                df_chunk = download_csv_chunk(session, dataset_id, extra_params=params)
                dfs.append(df_chunk)

        # 5) Combine all parts, save to a single CSV, return DataFrame
        if dfs:
            full_df = pd.concat(dfs, ignore_index=True)
        else:
            full_df = pd.DataFrame()

        data_path = ensure_data_dir()
        csv_path = os.path.join(data_path, f"{dataset_id}.csv")
        full_df.to_csv(csv_path, index=False)

        return full_df
    return (get_dataset,)

@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""## Load data""")
    return


@app.cell
def _(get_dataset):
    # Read the dataset
    df = get_dataset(dataset_id="100112")
    df
    return (df,)


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""## Analyze Data""")
    return


@app.cell
def _(df):
    # check missing values with missingno
    # https://github.com/ResidentMario/missingno
    import missingno as msno

    msno.matrix(df, labels=True, sort="descending")
    return


@app.cell
def _(df):
    df.info(memory_usage="deep", verbose=True)
    return


@app.cell
def _(df, pd, plt):
    # plot a histogram for each numerical feature
    try:
        df.hist(bins=25, rwidth=0.9)
        plt.tight_layout()
        plt.show()
    except ValueError:
        print("No numerical data to plot.")
    return

@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""**Questions about the data?** Open Data Basel-Stadt | opendata@bs.ch""")
    return

if __name__ == "__main__":
    app.run()
