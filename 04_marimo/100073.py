# /// script
# requires-python = ">=3.12"
# dependencies = [
#     "marimo",
#     "matplotlib==3.10.6",
#     "missingno==0.5.2",
#     "pandas==2.3.2",
#     "polars==1.32.3",
#     "requests==2.32.5",
# ]
# ///

import marimo

__generated_with = "0.15.1"
app = marimo.App(auto_download=["html"])


@app.cell
def _():
    import marimo as mo
    return (mo,)


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## Open Government Data, provided by **Statistisches Amt des Kantons Basel-Stadt - DCC Data Competence Center**
    *Autogenerated Python starter code for dataset with identifier* **100073**
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## Dataset
    # **Coronavirus (COVID-19): Fallzahlen Basel-Stadt**
    **Description**: <div><div>Anzahl Fälle der Coronavirus-Krankheit (COVID-19) in Basel-Stadt. Die Daten wurden zu Beginn der Pandemie durch Mitarbeiter von <span data-teams="true">Open Data Basel-Stadt </span>von Hand aus öffentlich zugänglichen offiziellen Quellen eingetippt. Später wurden die Daten aus den Bulletins des Gesundheitsdepartements Basel-Stadt automatisiert ausgelesen. Mittlerweile stammen die Angaben direkt von den medizinischen Diensten des Gesundheitsdepartements Basel-Stadt.</div><div><br></div><div>Die Quellenangabe der jeweiligen Zahlen sind direkt der Tabelle zu entnehmen. </div><div><br></div></div><div>Die offiziellen Daten aller Kantone und des Fürstentums Liechtenstein (FL) sind hier zu finden: </div><ul><li>Interaktives Dashboard der Zahlen aller Kantone: <a href="https://data.bs.ch/pages/covid-19-dashboard/">https://data.bs.ch/pages/covid-19-dashboard/</a></li><li>Alle Kantone und FL in einem File: <a href="https://github.com/openZH/covid_19/blob/master/COVID19_Fallzahlen_CH_total_v2.csv" target="_blank">https://github.com/openZH/covid_19/blob/master/COVID19_Fallzahlen_CH_total_v2.csv</a></li><li>Ein File pro Kanton (z.T. sind in den einzelnen Files zusätzliche Spalten vorhanden gegenüber dem gesamtschweizerischen File): <a href="https://github.com/openZH/covid_19/tree/master/fallzahlen_kanton_total_csv_v2" target="_blank">https://github.com/openZH/covid_19/tree/master/fallzahlen_kanton_total_csv_v2</a><a href="https://github.com/openZH/covid_19/tree/master/fallzahlen_kanton_total_csv_v2" target="_blank"></a></li></ul><p>Informationen zu den durchgeführten Tests auf täglicher Basis gemäss Bundesamt für Gesundheit (BAG) finden sich neu in diesem Datensatz: <a href="https://data.bs.ch/explore/dataset/100094/" target="_blank">https://data.bs.ch/explore/dataset/100094/</a></p><p>Daten zu Todesfällen von Personen mit SARS-CoV-2 mit Wohnsitz in Basel-Stadt sind in diesem Datensatz zu finden: <a href="https://data.bs.ch/explore/dataset/100076/" target="_blank">https://data.bs.ch/explore/dataset/100076/</a><a "="" href="https://data.bs.ch/explore/dataset/100076////" target="_blank"></a></p><p>Daten zu den 7- und 14-Tages Inzidenzen sowie den Fallzahlen pro Gemeinde (Basel, Riehen, Bettingen) sind in diesem Datensatz: <a href="https://data.bs.ch/explore/dataset/100108/" target="_blank">https://data.bs.ch/explore/dataset/100108/</a></p><p><b>Änderungsprotokoll:</b></p><ul><li>Ab dem 5.11.2020 wurden keine Angaben mehr zu positiv getesteten Personen mit Wohnsitz ausserhalb des Kantons Basel-Stadt gemacht. Dies, weil die Tests mittlerweile durch eine grössere Anzahl Laboratorien durchgeführt wurden und nicht mehr alle Resultate der ausserkantonalen und internationalen Fälle dem kantonsärztlichen Dienst Basel-Stadt gemeldet wurden.</li><li><span>Ab 18.6.2022 wurden am Samstag und Sonntag keine neuen Daten in diesen Datensatz publiziert. </span></li><li><span>Ab 1. Februar 2023 wurden die Daten jeweils am Dienstag und am Freitag aktualisiert.</span></li><li><span>Ab 4. April 2023 werden die Daten jeweils am Dienstag aktualisiert. Die Daten werden somit einmal wöchentlich aktualisiert.</span></li><li><span>Die Erhebung der Fallzahlen wurde per 5. Juli 2023 sistiert. Der Datensatz wird nicht mehr aktualisiert.</span> Aktualisierungsintervall von "DAILY" auf "NEVER" geändert.</li></ul><p><br></p>

    *You can find the dataset [under this link](https://data.bs.ch/explore/dataset/100073)*.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    /// details | Metadata

    - **Dataset_identifier** `100073`
- **Title** `Coronavirus (COVID-19): Fallzahlen Basel-Stadt`
- **Description** `<div><div>Anzahl Fälle der Coronavirus-Krankheit (COVID-19) in Basel-Stadt. Die Daten wurden zu Beginn der Pandemie durch Mitarbeiter von <span data-teams="true">Open Data Basel-Stadt </span>von Hand aus öffentlich zugänglichen offiziellen Quellen eingetippt. Später wurden die Daten aus den Bulletins des Gesundheitsdepartements Basel-Stadt automatisiert ausgelesen. Mittlerweile stammen die Angaben direkt von den medizinischen Diensten des Gesundheitsdepartements Basel-Stadt.</div><div><br></div><div>Die Quellenangabe der jeweiligen Zahlen sind direkt der Tabelle zu entnehmen. </div><div><br></div></div><div>Die offiziellen Daten aller Kantone und des Fürstentums Liechtenstein (FL) sind hier zu finden: </div><ul><li>Interaktives Dashboard der Zahlen aller Kantone: <a href="https://data.bs.ch/pages/covid-19-dashboard/">https://data.bs.ch/pages/covid-19-dashboard/</a></li><li>Alle Kantone und FL in einem File: <a href="https://github.com/openZH/covid_19/blob/master/COVID19_Fallzahlen_CH_total_v2.csv" target="_blank">https://github.com/openZH/covid_19/blob/master/COVID19_Fallzahlen_CH_total_v2.csv</a></li><li>Ein File pro Kanton (z.T. sind in den einzelnen Files zusätzliche Spalten vorhanden gegenüber dem gesamtschweizerischen File): <a href="https://github.com/openZH/covid_19/tree/master/fallzahlen_kanton_total_csv_v2" target="_blank">https://github.com/openZH/covid_19/tree/master/fallzahlen_kanton_total_csv_v2</a><a href="https://github.com/openZH/covid_19/tree/master/fallzahlen_kanton_total_csv_v2" target="_blank"></a></li></ul><p>Informationen zu den durchgeführten Tests auf täglicher Basis gemäss Bundesamt für Gesundheit (BAG) finden sich neu in diesem Datensatz: <a href="https://data.bs.ch/explore/dataset/100094/" target="_blank">https://data.bs.ch/explore/dataset/100094/</a></p><p>Daten zu Todesfällen von Personen mit SARS-CoV-2 mit Wohnsitz in Basel-Stadt sind in diesem Datensatz zu finden: <a href="https://data.bs.ch/explore/dataset/100076/" target="_blank">https://data.bs.ch/explore/dataset/100076/</a><a "="" href="https://data.bs.ch/explore/dataset/100076////" target="_blank"></a></p><p>Daten zu den 7- und 14-Tages Inzidenzen sowie den Fallzahlen pro Gemeinde (Basel, Riehen, Bettingen) sind in diesem Datensatz: <a href="https://data.bs.ch/explore/dataset/100108/" target="_blank">https://data.bs.ch/explore/dataset/100108/</a></p><p><b>Änderungsprotokoll:</b></p><ul><li>Ab dem 5.11.2020 wurden keine Angaben mehr zu positiv getesteten Personen mit Wohnsitz ausserhalb des Kantons Basel-Stadt gemacht. Dies, weil die Tests mittlerweile durch eine grössere Anzahl Laboratorien durchgeführt wurden und nicht mehr alle Resultate der ausserkantonalen und internationalen Fälle dem kantonsärztlichen Dienst Basel-Stadt gemeldet wurden.</li><li><span>Ab 18.6.2022 wurden am Samstag und Sonntag keine neuen Daten in diesen Datensatz publiziert. </span></li><li><span>Ab 1. Februar 2023 wurden die Daten jeweils am Dienstag und am Freitag aktualisiert.</span></li><li><span>Ab 4. April 2023 werden die Daten jeweils am Dienstag aktualisiert. Die Daten werden somit einmal wöchentlich aktualisiert.</span></li><li><span>Die Erhebung der Fallzahlen wurde per 5. Juli 2023 sistiert. Der Datensatz wird nicht mehr aktualisiert.</span> Aktualisierungsintervall von "DAILY" auf "NEVER" geändert.</li></ul><p><br></p>`
- **Contact_name** `Open Data Basel-Stadt`
- **Issued** `2020-04-06`
- **Modified** `2023-07-05T07:40:31+00:00`
- **Rights** `NonCommercialAllowed-CommercialAllowed-ReferenceRequired`
- **Temporal_coverage_start_date** `2020-02-26T23:00:00+00:00`
- **Temporal_coverage_end_date** `2023-07-03T22:00:00+00:00`
- **Themes** `['Gesundheit']`
- **Keywords** `['Coronavirus', 'Virus', 'COVID-19', 'Krankheit', 'Spital', 'Quarantäne', 'Todesfälle', 'Lungenentzündung', 'Pandemie', 'Corona']`
- **Publisher** `Open Data Basel-Stadt`
- **Reference** `None`


    ///
    """
    )
    return


@app.cell
def _():
    import os
    import io
    import pandas as pd
    import requests
    import matplotlib.pyplot as plt
    return os, io, pd, plt, requests


@app.cell
def _(plt):
    plt.style.use("ggplot")

    params = {
        "text.color": (0.25, 0.25, 0.25),
        "figure.figsize": [18, 6],
    }

    plt.rcParams.update(params)
    return


@app.cell
def _(os):
    def ensure_data_dir() -> str:
        data_path = os.path.join(os.getcwd(), "..", "data")
        os.makedirs(data_path, exist_ok=True)
        return data_path
    return (ensure_data_dir,)


@app.cell
def _(io, pd, requests):
    def download_csv_chunk(
        session: requests.Session,
        dataset_id: str,
        extra_params: dict | None = None,
    ) -> pd.DataFrame:
        base_url = "https://data.bs.ch/api/explore/v2.1"
        url = f"{base_url}/catalog/datasets/{dataset_id}/exports/csv"

        params = {
            "timezone": "Europe/Zurich",
            "use_labels": "false",
        }
        if extra_params:
            params.update(extra_params)

        r = session.get(url, params=params)
        r.raise_for_status()

        buf = io.BytesIO(r.content)

        df = pd.read_csv(
            buf,
            sep=";",
            on_bad_lines="warn",
            encoding_errors="ignore",
            low_memory=False,
        )

        return df
    return (download_csv_chunk,)


@app.cell
def _():
    def pick_best_facet(facets_json: dict, max_rows_per_chunk: int) -> tuple[str | None, list[str]]:
        """
        Choose a facet column where each bucket has <= max_rows_per_chunk rows.
        Among all such columns, pick the one with the smallest worst-case bucket.
        Returns (facet_name, list_of_values) or (None, []) if nothing suitable.
        """
        best_name = None
        best_values: list[str] = []
        best_max_bucket = None

        for facet in facets_json.get("facets", []):
            facet_name = facet.get("name")
            value_list = facet.get("facets", [])
            if not facet_name or not value_list:
                continue

            counts = [v.get("count", 0) for v in value_list]
            if not counts:
                continue

            max_bucket = max(counts)
            if max_bucket > max_rows_per_chunk:
                # this facet would still exceed the chunk limit for some values
                continue

            if best_max_bucket is None or max_bucket < best_max_bucket:
                best_max_bucket = max_bucket
                best_name = facet_name
                best_values = [v.get("value") for v in value_list if v.get("value") is not None]

        return best_name, best_values


@app.cell
def _(download_csv_chunk, ensure_data_dir, mo, os, pd, requests):
    def get_dataset(dataset_id: str, max_rows_per_chunk: int = 50_000) -> pd.DataFrame:
        """
        Download a dataset from data.bs.ch.

        - For small datasets (<= max_rows_per_chunk): single CSV export.
        - For large datasets:
            * Inspect /facets to find a good splitting column.
            * Download one CSV per facet value via refine.<col>=<value>.
            * Additionally download rows where that column is NULL via q=#null(<col>).

        The combined result is written to ../data/{dataset_id}.csv and returned as a DataFrame.
        """
        base_url = "https://data.bs.ch/api/explore/v2.1"
        records_url = f"{base_url}/catalog/datasets/{dataset_id}/records"
        facets_url = f"{base_url}/catalog/datasets/{dataset_id}/facets"

        session = requests.Session()
        common_params = {
            "timezone": "Europe/Zurich",
            "use_labels": "false",
        }

        # 1) Get total_count via /records
        r = session.get(records_url, params={**common_params, "limit": 1})
        r.raise_for_status()
        meta = r.json()
        total_count = meta.get("total_count", 0)

        if not isinstance(total_count, int):
            # fall back to simple export if we can't read total_count
            total_count = 0

        # 2) Small dataset: single CSV export
        if total_count == 0 or total_count <= max_rows_per_chunk:
            df = download_csv_chunk(session, dataset_id, extra_params={})
            data_path = ensure_data_dir()
            csv_path = os.path.join(data_path, f"{dataset_id}.csv")
            df.to_csv(csv_path, index=False)
            return df

        # 3) Large dataset: inspect /facets to decide how to split
        r = session.get(facets_url, params=common_params)
        r.raise_for_status()
        facets_json = r.json()

        facet_name, facet_values = pick_best_facet(facets_json, max_rows_per_chunk=max_rows_per_chunk)

        if facet_name is None or not facet_values:
            raise RuntimeError(
                f"Could not find a facet column to split dataset {dataset_id} into "
                f"chunks of <= {max_rows_per_chunk} rows. Please handle this dataset manually."
            )

        dfs: list[pd.DataFrame] = []

        # 4) Download each facet value (refine.<facet_name>=value)
        n_parts = len(facet_values) + 1  # +1 for NULLs

        with mo.status.progress_bar(
            total=n_parts,
            title=f"Lade Datensatz {dataset_id}",
            subtitle=f"Split nach '{facet_name}'…",
        ) as bar:
            # NULLs
            bar.update(subtitle=f"{facet_name} = NULL")
            null_query = {"qv1": f"#null({facet_name})"}
            try:
                df_null = download_csv_chunk(session, dataset_id, extra_params=null_query)
                if not df_null.empty:
                    dfs.append(df_null)
            except requests.HTTPError as e:
                print(f"Warning: NULL download for {facet_name} failed: {e}")
            # non-NULL values
            for v in facet_values:
                bar.update(subtitle=f"{facet_name} = {v!r}")
                params = {"refine": f'{facet_name}:"{v}"'}
                df_chunk = download_csv_chunk(session, dataset_id, extra_params=params)
                dfs.append(df_chunk)

        # 5) Combine all parts, save to a single CSV, return DataFrame
        if dfs:
            full_df = pd.concat(dfs, ignore_index=True)
        else:
            full_df = pd.DataFrame()

        data_path = ensure_data_dir()
        csv_path = os.path.join(data_path, f"{dataset_id}.csv")
        full_df.to_csv(csv_path, index=False)

        return full_df
    return (get_dataset,)

@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""## Load data""")
    return


@app.cell
def _(get_dataset):
    # Read the dataset
    df = get_dataset(dataset_id="100073")
    df
    return (df,)


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""## Analyze Data""")
    return


@app.cell
def _(df):
    # check missing values with missingno
    # https://github.com/ResidentMario/missingno
    import missingno as msno

    msno.matrix(df, labels=True, sort="descending")
    return


@app.cell
def _(df):
    df.info(memory_usage="deep", verbose=True)
    return


@app.cell
def _(df, pd, plt):
    # plot a histogram for each numerical feature
    try:
        df.hist(bins=25, rwidth=0.9)
        plt.tight_layout()
        plt.show()
    except ValueError:
        print("No numerical data to plot.")
    return

@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""**Questions about the data?** Open Data Basel-Stadt | opendata@bs.ch""")
    return

if __name__ == "__main__":
    app.run()
