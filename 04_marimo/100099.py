# /// script
# requires-python = ">=3.12"
# dependencies = [
#     "marimo",
#     "matplotlib==3.10.6",
#     "missingno==0.5.2",
#     "pandas==2.3.2",
#     "polars==1.32.3",
#     "requests==2.32.5",
# ]
# ///

import marimo

__generated_with = "0.15.1"
app = marimo.App(auto_download=["html"])


@app.cell
def _():
    import marimo as mo
    return (mo,)


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## Open Government Data, provided by **Statistisches Amt des Kantons Basel-Stadt - DCC Data Competence Center**
    *Autogenerated Python starter code for dataset with identifier* **100099**
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## Dataset
    # **Geborene nach Geschlecht, Staatsangehörigkeit und Geburtsmonat**
    **Description**: Dieser Datensatz zeigt die Geborenen im Kanton Basel-Stadt nach Geschlecht, Staatsangehörigkeit und Geburtsmonat sowie nach Alter, Staatsangehörigkeit und Zivilstand der Eltern. Die Daten werden monatlich aktualisiert, wobei die Zahlen eines Monats jeweils am 16. Tag des nächsten Monats publiziert werden. Aufgrund von Nachmeldungen kann es jederzeit zu Änderungen bei bereits veröffentlichten Werten kommen. In den Daten des laufenden Jahres und bis ca. Juli auch in jenen des zurückliegenden Jahres sind ausser den Lebendgeborenen auch die Totgeborenen berücksichtigt, weil die Angabe zur Lebensfähigkeit jeweils erst im Juli des Folgejahres verfügbar ist. In weiter zurückliegenden Jahren sind nur die Lebendgeborenen berücksichtigt. Auch die Angaben zur Geburtenfolge und zum Zivilstand der Eltern sind jeweils erst im Juli des Folgejahres verfügbar.Die hier veröffentlichten Werte können aus methodischen Gründen von denjenigen in der kantonalen öffentlichen Statistik <a href="https://statistik.bs.ch/unterthema/3" target="_blank">(https://statistik.bs.ch/unterthema/3)</a> abweichen: In Letzterer werden nachträglich gemeldete Geburten während vier Monaten gesammelt, danach gelten die Zahlen als definitiv. Später eintreffende Meldungen werden im letzten noch nicht abgeschlossenen Monat gezählt. In diesem Datensatz werden sie im Monat des Geburtsdatums gezählt.Aus Gründen des Persönlichkeitsschutzes können im Datensatz mit dem Geburtsdatum <a href="https://data.bs.ch/explore/dataset/100092/" target="_blank">(https://data.bs.ch/explore/dataset/100092/)</a> weniger Attribute veröffentlicht werden als im vorliegenden Datensatz. Quelle: Statistisches Amt Basel-Stadt, Bevölkerungsstatistik.

    *You can find the dataset [under this link](https://data.bs.ch/explore/dataset/100099)*.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    /// details | Metadata

    - **Dataset_identifier** `100099`
- **Title** `Geborene nach Geschlecht, Staatsangehörigkeit und Geburtsmonat`
- **Description** `Dieser Datensatz zeigt die Geborenen im Kanton Basel-Stadt nach Geschlecht, Staatsangehörigkeit und Geburtsmonat sowie nach Alter, Staatsangehörigkeit und Zivilstand der Eltern. Die Daten werden monatlich aktualisiert, wobei die Zahlen eines Monats jeweils am 16. Tag des nächsten Monats publiziert werden. Aufgrund von Nachmeldungen kann es jederzeit zu Änderungen bei bereits veröffentlichten Werten kommen. In den Daten des laufenden Jahres und bis ca. Juli auch in jenen des zurückliegenden Jahres sind ausser den Lebendgeborenen auch die Totgeborenen berücksichtigt, weil die Angabe zur Lebensfähigkeit jeweils erst im Juli des Folgejahres verfügbar ist. In weiter zurückliegenden Jahren sind nur die Lebendgeborenen berücksichtigt. Auch die Angaben zur Geburtenfolge und zum Zivilstand der Eltern sind jeweils erst im Juli des Folgejahres verfügbar.Die hier veröffentlichten Werte können aus methodischen Gründen von denjenigen in der kantonalen öffentlichen Statistik <a href="https://statistik.bs.ch/unterthema/3" target="_blank">(https://statistik.bs.ch/unterthema/3)</a> abweichen: In Letzterer werden nachträglich gemeldete Geburten während vier Monaten gesammelt, danach gelten die Zahlen als definitiv. Später eintreffende Meldungen werden im letzten noch nicht abgeschlossenen Monat gezählt. In diesem Datensatz werden sie im Monat des Geburtsdatums gezählt.Aus Gründen des Persönlichkeitsschutzes können im Datensatz mit dem Geburtsdatum <a href="https://data.bs.ch/explore/dataset/100092/" target="_blank">(https://data.bs.ch/explore/dataset/100092/)</a> weniger Attribute veröffentlicht werden als im vorliegenden Datensatz. Quelle: Statistisches Amt Basel-Stadt, Bevölkerungsstatistik.`
- **Contact_name** `Open Data Basel-Stadt`
- **Issued** `2021-01-19`
- **Modified** `2026-01-05T02:16:15+00:00`
- **Rights** `NonCommercialAllowed-CommercialAllowed-ReferenceRequired`
- **Temporal_coverage_start_date** `None`
- **Temporal_coverage_end_date** `None`
- **Themes** `['Bevölkerung']`
- **Keywords** `['Alter', 'Altersstruktur', 'Bevölkerungsbestand', 'Demographie', 'Geburtsort', 'Familie', 'Haushalt', 'Geburten', 'Bevölkerungsstruktur', 'Neugeboren']`
- **Publisher** `Statistisches Amt`
- **Reference** `None`


    ///
    """
    )
    return


@app.cell
def _():
    import os
    import io
    import pandas as pd
    import requests
    import matplotlib.pyplot as plt
    return os, io, pd, plt, requests


@app.cell
def _(plt):
    plt.style.use("ggplot")

    params = {
        "text.color": (0.25, 0.25, 0.25),
        "figure.figsize": [18, 6],
    }

    plt.rcParams.update(params)
    return


@app.cell
def _(os):
    def ensure_data_dir() -> str:
        data_path = os.path.join(os.getcwd(), "..", "data")
        os.makedirs(data_path, exist_ok=True)
        return data_path
    return (ensure_data_dir,)


@app.cell
def _(io, pd, requests):
    def download_csv_chunk(
        session: requests.Session,
        dataset_id: str,
        extra_params: dict | None = None,
    ) -> pd.DataFrame:
        base_url = "https://data.bs.ch/api/explore/v2.1"
        url = f"{base_url}/catalog/datasets/{dataset_id}/exports/csv"

        params = {
            "timezone": "Europe/Zurich",
            "use_labels": "false",
        }
        if extra_params:
            params.update(extra_params)

        r = session.get(url, params=params)
        r.raise_for_status()

        buf = io.BytesIO(r.content)

        df = pd.read_csv(
            buf,
            sep=";",
            on_bad_lines="warn",
            encoding_errors="ignore",
            low_memory=False,
        )

        return df
    return (download_csv_chunk,)


@app.cell
def _():
    def pick_best_facet(facets_json: dict, max_rows_per_chunk: int) -> tuple[str | None, list[str]]:
        """
        Choose a facet column where each bucket has <= max_rows_per_chunk rows.
        Among all such columns, pick the one with the smallest worst-case bucket.
        Returns (facet_name, list_of_values) or (None, []) if nothing suitable.
        """
        best_name = None
        best_values: list[str] = []
        best_max_bucket = None

        for facet in facets_json.get("facets", []):
            facet_name = facet.get("name")
            value_list = facet.get("facets", [])
            if not facet_name or not value_list:
                continue

            counts = [v.get("count", 0) for v in value_list]
            if not counts:
                continue

            max_bucket = max(counts)
            if max_bucket > max_rows_per_chunk:
                # this facet would still exceed the chunk limit for some values
                continue

            if best_max_bucket is None or max_bucket < best_max_bucket:
                best_max_bucket = max_bucket
                best_name = facet_name
                best_values = [v.get("value") for v in value_list if v.get("value") is not None]

        return best_name, best_values


@app.cell
def _(download_csv_chunk, ensure_data_dir, mo, os, pd, requests):
    def get_dataset(dataset_id: str, max_rows_per_chunk: int = 50_000) -> pd.DataFrame:
        """
        Download a dataset from data.bs.ch.

        - For small datasets (<= max_rows_per_chunk): single CSV export.
        - For large datasets:
            * Inspect /facets to find a good splitting column.
            * Download one CSV per facet value via refine.<col>=<value>.
            * Additionally download rows where that column is NULL via q=#null(<col>).

        The combined result is written to ../data/{dataset_id}.csv and returned as a DataFrame.
        """
        base_url = "https://data.bs.ch/api/explore/v2.1"
        records_url = f"{base_url}/catalog/datasets/{dataset_id}/records"
        facets_url = f"{base_url}/catalog/datasets/{dataset_id}/facets"

        session = requests.Session()
        common_params = {
            "timezone": "Europe/Zurich",
            "use_labels": "false",
        }

        # 1) Get total_count via /records
        r = session.get(records_url, params={**common_params, "limit": 1})
        r.raise_for_status()
        meta = r.json()
        total_count = meta.get("total_count", 0)

        if not isinstance(total_count, int):
            # fall back to simple export if we can't read total_count
            total_count = 0

        # 2) Small dataset: single CSV export
        if total_count == 0 or total_count <= max_rows_per_chunk:
            df = download_csv_chunk(session, dataset_id, extra_params={})
            data_path = ensure_data_dir()
            csv_path = os.path.join(data_path, f"{dataset_id}.csv")
            df.to_csv(csv_path, index=False)
            return df

        # 3) Large dataset: inspect /facets to decide how to split
        r = session.get(facets_url, params=common_params)
        r.raise_for_status()
        facets_json = r.json()

        facet_name, facet_values = pick_best_facet(facets_json, max_rows_per_chunk=max_rows_per_chunk)

        if facet_name is None or not facet_values:
            raise RuntimeError(
                f"Could not find a facet column to split dataset {dataset_id} into "
                f"chunks of <= {max_rows_per_chunk} rows. Please handle this dataset manually."
            )

        dfs: list[pd.DataFrame] = []

        # 4) Download each facet value (refine.<facet_name>=value)
        n_parts = len(facet_values) + 1  # +1 for NULLs

        with mo.status.progress_bar(
            total=n_parts,
            title=f"Lade Datensatz {dataset_id}",
            subtitle=f"Split nach '{facet_name}'…",
        ) as bar:
            # NULLs
            bar.update(subtitle=f"{facet_name} = NULL")
            null_query = {"qv1": f"#null({facet_name})"}
            try:
                df_null = download_csv_chunk(session, dataset_id, extra_params=null_query)
                if not df_null.empty:
                    dfs.append(df_null)
            except requests.HTTPError as e:
                print(f"Warning: NULL download for {facet_name} failed: {e}")
            # non-NULL values
            for v in facet_values:
                bar.update(subtitle=f"{facet_name} = {v!r}")
                params = {"refine": f'{facet_name}:"{v}"'}
                df_chunk = download_csv_chunk(session, dataset_id, extra_params=params)
                dfs.append(df_chunk)

        # 5) Combine all parts, save to a single CSV, return DataFrame
        if dfs:
            full_df = pd.concat(dfs, ignore_index=True)
        else:
            full_df = pd.DataFrame()

        data_path = ensure_data_dir()
        csv_path = os.path.join(data_path, f"{dataset_id}.csv")
        full_df.to_csv(csv_path, index=False)

        return full_df
    return (get_dataset,)

@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""## Load data""")
    return


@app.cell
def _(get_dataset):
    # Read the dataset
    df = get_dataset(dataset_id="100099")
    df
    return (df,)


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""## Analyze Data""")
    return


@app.cell
def _(df):
    # check missing values with missingno
    # https://github.com/ResidentMario/missingno
    import missingno as msno

    msno.matrix(df, labels=True, sort="descending")
    return


@app.cell
def _(df):
    df.info(memory_usage="deep", verbose=True)
    return


@app.cell
def _(df, pd, plt):
    # plot a histogram for each numerical feature
    try:
        df.hist(bins=25, rwidth=0.9)
        plt.tight_layout()
        plt.show()
    except ValueError:
        print("No numerical data to plot.")
    return

@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""**Questions about the data?** Open Data Basel-Stadt | opendata@bs.ch""")
    return

if __name__ == "__main__":
    app.run()
